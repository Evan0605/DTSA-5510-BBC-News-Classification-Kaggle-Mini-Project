{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation, digits\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "color = ['#247BA0', '#F6511D', '#7FB800', '#FFB400', '#F25F5C', '#50514F']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the this project is to use machine learning algorithm to categorize article based on the text content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data files first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_train_df = pd.read_csv('BBC News Train.csv')\n",
    "bbc_test_df = pd.read_csv('BBC News Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset contains 1,490 samples, and each row consists of the article id, content and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ArticleId  1490 non-null   int64 \n",
      " 1   Text       1490 non-null   object\n",
      " 2   Category   1490 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 35.0+ KB\n"
     ]
    }
   ],
   "source": [
    "bbc_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset seems to be balance, the number of sport and business articles are slightly more than other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            346\n",
       "business         336\n",
       "politics         274\n",
       "entertainment    273\n",
       "tech             261\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_train_df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23dcd664190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bbc_train_df['Category'].value_counts().plot.bar(x = 'lab', y = 'val', rot = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the text content by transforming into lower letters, removing stop words and punctuation, and lemmatizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_train_df['clean_text'] = bbc_train_df['Text'].str.lower()\n",
    "stop_words = list(stopwords.words('english'))\n",
    "punctuation = list(punctuation)\n",
    "clean_text_list = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for row in bbc_train_df['clean_text']:\n",
    "    text_split = row.split()\n",
    "    clean_temp = [lemmatizer.lemmatize(word) for word in text_split if word not in stop_words and word not in punctuation]\n",
    "    clean_temp = ' '.join(clean_temp)\n",
    "    clean_text_list.append(clean_temp)\n",
    "bbc_train_df['clean_text'] = pd.Series(clean_text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scikit learn TfidfVectorizer function to extract features from raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.95, min_df = 2,\n",
    "                                   max_features = 1000,\n",
    "                                   stop_words = 'english')\n",
    "tfidvec_train = tfidf_vectorizer.fit_transform(bbc_train_df['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building predict function to transform tfidf matrix in to prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(nmf_matrix):\n",
    "    sorted_index = np.argsort(nmf_matrix)\n",
    "    n_sample, n_cat = sorted_index.shape\n",
    "    prediction = [[sorted_index[i][n_cat - 1]] for i in range(n_sample)]\n",
    "    cat = np.empty(n_sample, dtype = np.int64)\n",
    "    for i in range(n_sample):\n",
    "        cat[i] = prediction[i][0]\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building label_permute_compare function to calculate model accuracy and return label order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_permute_compare(ytdf,yp,n=5):\n",
    "    acc = 0\n",
    "    labelorder = ()\n",
    "    for e in itertools.permutations(ytdf['Category'].unique()):\n",
    "        df_label = pd.DataFrame({'model_label': range(5), 'model_Category': list(e)})\n",
    "        df_model_label = pd.merge(pd.DataFrame({'model_label': yp, 'true_Category': ytdf['Category']}), df_label, on = 'model_label')\n",
    "        accuracy_c = df_model_label[df_model_label['true_Category']==df_model_label['model_Category']].shape[0]/df_model_label.shape[0]\n",
    "        if accuracy_c > acc:\n",
    "            acc = accuracy_c\n",
    "            labelorder = tuple(pd.merge(pd.DataFrame({'model_Category': ytdf['Category'].unique()}),\n",
    "                                        df_label, how = 'left')['model_label'])\n",
    "            label_order = df_label\n",
    "    return (labelorder, acc, label_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying different combinations of attributes in the NMF model to find out the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nndsvd cd frobenius 0.8919463087248322\n",
      "nndsvd mu frobenius 0.8798657718120806\n",
      "nndsvd mu kullback-leibler 0.9114093959731544\n",
      "nndsvda cd frobenius 0.8919463087248322\n",
      "nndsvda mu frobenius 0.9013422818791946\n",
      "nndsvda mu kullback-leibler 0.9476510067114094\n",
      "nndsvdar cd frobenius 0.8919463087248322\n",
      "nndsvdar mu frobenius 0.9026845637583892\n",
      "nndsvdar mu kullback-leibler 0.9476510067114094\n"
     ]
    }
   ],
   "source": [
    "best_init = ''\n",
    "best_solver = ''\n",
    "best_beta_loss = ''\n",
    "best_acc= 0\n",
    "\n",
    "for init in ['nndsvd', 'nndsvda', 'nndsvdar']:\n",
    "    for solver in ['cd', 'mu']:\n",
    "        for beta_loss in ['frobenius', 'kullback-leibler', 'itakura-saito']:\n",
    "            try:\n",
    "                nmf = NMF(n_components = 5, random_state = 1, l1_ratio = 0.5,\n",
    "                      init = init,\n",
    "                      solver = solver,\n",
    "                      beta_loss = beta_loss).fit(tfidvec_train)\n",
    "                nmf_matrix = nmf.transform(tfidvec_train)\n",
    "                yp = predict(nmf_matrix)\n",
    "                labelorder, acc, label_order = label_permute_compare(bbc_train_df, yp, n = 5)\n",
    "                print(init, solver, beta_loss, acc)\n",
    "                if acc > best_acc:\n",
    "                    best_acc= acc\n",
    "                    best_init = init\n",
    "                    best_solver = solver\n",
    "                    best_beta_loss = beta_loss\n",
    "            except:    \n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nndsvda mu kullback-leibler  leads the best performance.\n",
      "(3, 4, 0, 1, 2) accuracy is 0.9476510067114094\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components = 5, random_state = 1, l1_ratio = 0.5,\n",
    "          init = best_init,\n",
    "          solver = best_solver,\n",
    "          beta_loss = best_beta_loss).fit(tfidvec_train)\n",
    "nmf_matrix = nmf.transform(tfidvec_train)\n",
    "yp = predict(nmf_matrix)\n",
    "labelorder, acc, label_order = label_permute_compare(bbc_train_df, yp, n = 5)\n",
    "print(best_init, best_solver, best_beta_loss, ' leads the best performance.')\n",
    "print(str(labelorder) + ' accuracy is ' +  str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_test_df['clean_text'] = bbc_test_df['Text'].str.lower()\n",
    "stop_words = list(stopwords.words('english'))\n",
    "punctuation = list(punctuation)\n",
    "clean_text_list = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for row in bbc_test_df['clean_text']:\n",
    "    text_split = row.split()\n",
    "    clean_temp = [lemmatizer.lemmatize(word) for word in text_split if word not in stop_words and word not in punctuation]\n",
    "    clean_temp = ' '.join(clean_temp)\n",
    "    clean_text_list.append(clean_temp)\n",
    "bbc_test_df['clean_text'] = pd.Series(clean_text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the model above to make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidvec_test = tfidf_vectorizer.transform(bbc_test_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_matrix_test = nmf.transform(tfidvec_test)\n",
    "yp_test = predict(nmf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_label_test = pd.merge(pd.DataFrame({'ArticleId': bbc_test_df['ArticleId'], 'model_label': yp_test}), label_order, on = 'model_label', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_nmf = df_model_label_test[['ArticleId', 'model_Category']]\n",
    "submission_nmf.columns = ['ArticleId', 'Category']\n",
    "submission_nmf.to_csv('submission_nmf.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission scores 0.93877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we use supervised machine learning random forest to make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = bbc_train_df['clean_text']\n",
    "Y_train = bbc_train_df['Category']\n",
    "X_test = bbc_test_df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tffidf', TfidfVectorizer()),\n",
       "                ('clf', RandomForestClassifier())])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([('tffidf', TfidfVectorizer()),\n",
    "                ('clf', RandomForestClassifier(n_estimators=100))])\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_randomforest = pd.DataFrame({'ArticleId': bbc_test_df['ArticleId'], 'Category': Y_predict})\n",
    "submission_randomforest.to_csv('submission_randomforest.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission scores 0.96326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Non-Negative Matrix Factorization, we have a training score of 94.77%, and the test score is 93.88%. Using Random Forest Classifier, we have a training score of 100%, and the test score is 96.32%. It seems that supervised machine learning got a better result by comparing with unsupervised machine learning, but overall the results of these models are both good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
